{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Lab 06</h1>\n",
        "<h4>Name : Ambalia Harshit</h4>\n",
        "<h4>Roll No. : MT001</h4>\n",
        "\n",
        "<h3>AIM : Introduction Logistic Regression</h3>"
      ],
      "metadata": {
        "id": "nQoCH4D3Rg6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: The AirBnB NYC 2019 Dataset + EDA\n",
        "Our goal is to predict the price of unseen housing units as being 'affordable' or 'unaffordable', by using their features.\n",
        "\n",
        "We will assume that this task is for a particular client who has a specific budget and would like to simplify the problem by classifying any unit that costs \\< $150 per night as 'affordable' and any unit that costs \\$150 or great as 'unaffordable'.\n"
      ],
      "metadata": {
        "id": "wbRWsJcqdOI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### It's all preprocessing\n",
        "\n",
        "### We are creating new column which is used as label\n",
        "#   df['affordable'] = np.where(df['price'] < 150, 1, 0)\n",
        "\n",
        "### Renaming the column so that naming confusion can be reduced\n",
        "#   df.rename(columns={\"neighbourhood_group\": \"borough\"}, inplace=True)\n",
        "\n",
        "### Now we are understanding the data, ie. price(on which our label is decided) can't be 0. So removing all rows where price=0\n",
        "# to get information about data\n",
        "#   df['price'].describe()\n",
        "# removing rows where price=0\n",
        "#   df = df.loc[df['price'] != 0]\n",
        "\n",
        "### Now we are dividing data into train, test and validation purpose.\n",
        "# Dividing entire data into train and test data, 80% for train, 20% for test.\n",
        "#   df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['affordable'])\n",
        "# Dividing train data into train and validation data.\n",
        "#   df_train, df_dev = train_test_split(df_train, test_size=0.25, random_state=99) #stratify=df_train['affordable'])\n",
        "\n",
        "### Now we are removing the target value from our current dataframes.\n",
        "# Saperating data(x_train) and feature(y_train) from : training data\n",
        "#   x_train = df_train.drop(['price', 'affordable'], axis=1)\n",
        "#   y_train = pd.DataFrame(data=df_train['affordable'], columns=[\"affordable\"])\n",
        "# Saperating data(x_dev) and feature(y_dev) from : Validation data\n",
        "#   x_dev = df_dev.drop(['price', 'affordable'], axis=1)\n",
        "#   y_dev = pd.DataFrame(data=df_dev['affordable'], columns=[\"affordable\"])\n",
        "# Saperating data(x_test) and feature(y_test) from : Testing data\n",
        "#   x_test = df_test.drop(['price', 'affordable'], axis=1)\n",
        "#   y_test = pd.DataFrame(data=df_test['affordable'], columns=[\"affordable\"])\n",
        "\n",
        "### Now we are printing count of NULL values for each column\n",
        "#   for col in x_train.columns:\n",
        "#       print(col, \":\", np.sum([x_train[col].isnull()]))\n",
        "\n",
        "### Now we are dropping the columns which have too many NULL values.\n",
        "#   x_train = x_train.drop(['last_review', 'reviews_per_month'], axis=1)\n",
        "#   x_dev = x_dev.drop(['last_review', 'reviews_per_month'], axis=1)\n",
        "#   x_test = x_test.drop(['last_review', 'reviews_per_month'], axis=1)\n",
        "\n",
        "### Now we are creating mask using a condition and using mask dropping the unwanted rows\n",
        "# only trimmed our training data, not our development or testing data, because in real scenarios, we would not know the nature of the testing data values.\n",
        "#   good_subset = x_train['minimum_nights'] <= 30\n",
        "#   x_train = x_train.loc[good_subset]\n",
        "#   y_train = y_train.loc[good_subset]\n",
        "\n",
        "### Printing columns names\n",
        "#   [col for col in x_train.columns]\n",
        "\n",
        "### Now we are scattering the plot graph for remaining features\n",
        "#   scatter_matrix(x_train, figsize=(30,20));"
      ],
      "metadata": {
        "id": "Byzwkzgl4g1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2** : Predicting with MLE(Maximum-likelihood estimation)\n"
      ],
      "metadata": {
        "id": "HjEfPWMZmICY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### does not require learning any weight/coefficient parameters.\n",
        "# Specifically, MLE selects the parameter value (y) that makes the observed data most probable, so as to maximize the likelihood function.\n",
        "#   mle_y = y_train['affordable'].value_counts().idxmax()\n",
        "#   dev_accuracy = y_dev['affordable'].value_counts()[mle_y] / len(y_dev['affordable'])\n",
        "#   dev_accuracy"
      ],
      "metadata": {
        "id": "FZ5E_RY5mGeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3 : Predicting with Linear Regression"
      ],
      "metadata": {
        "id": "vMNSeOYQmsSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### As this model needs only numeric values, not textual ones, we'll use only features which have numeric data.\n",
        "# We'll check for columns, if encoding is possible, we'll perform the label encoding and remove that encoded column.\n",
        "#   x_train = pd.get_dummies(x_train, columns=['borough', 'room_type'], drop_first=True)\n",
        "# Here we are dropping the unwanted columns.\n",
        "#   x_train = x_train.drop(['id', 'name', 'host_id', 'host_name', 'neighbourhood'], axis=1)\n",
        "\n",
        "### Now we are adding a constant term (usually denoted as β​ or bias term) to the feature matrix x_train.\n",
        "# This constant term is necessary when performing linear regression because it represents the intercept of the linear equation.\n",
        "# Without this constant term, the linear regression model would be forced to go through the origin (0,0), which might not be appropriate for the given data.\n",
        "#   x_train_padded = sm.add_constant(x_train)\n",
        "#   x_dev_padded = sm.add_constant(x_dev)\n",
        "# After this line of code, x_train_padded contains the original features from x_train with an additional column of ones (representing the constant term) added to the beginning of the feature matrix.\n",
        "#   y_train_lr = y_train['affordable'].values.reshape(-1, 1)\n",
        "#   y_dev_lr = y_dev['affordable'].values.reshape(-1,1)\n",
        "\n",
        "### Now we are training our model\n",
        "#   model = OLS(y_train_lr, x_train_padded)\n",
        "#   results = model.fit()\n",
        "#   results.summary()\n",
        "\n",
        "### Printing r2 score\n",
        "# calculating and reporting the requested values, particularly the Test R^2\n",
        "#   print('Train R^2 = {:.4}'.format(results.rsquared))\n",
        "#   print('Test R^2 = {:.4}'.format(r2_score(y_dev_lr, y_hat_dev)))\n",
        "\n",
        "### Checking accuracy or our model\n",
        "#   y_hat_dev = results.predict(exog=x_dev_padded)\n",
        "#   accuracy_score(y_dev, np.round(y_hat_dev))\n",
        "\n",
        "### Now we are appling lasso and ridge to out model with different values of alpha to find the best accuracy\n",
        "#   best_accuracy = -1\n",
        "#   best_model = None\n",
        "#   for cur_alpha in [0.001, .01, .05, .1, .5, 1, 5, 10, 50, 100, 500]:\n",
        "#       # fit (using Ridge Regression), predict, and score\n",
        "#       fitted_ridge = Ridge(alpha=cur_alpha).fit(x_train, y_train_lr)\n",
        "#       y_hat_dev = fitted_ridge.predict(x_dev).reshape(1,-1)[0]\n",
        "#       cur_accuracy = accuracy_score(y_dev['affordable'].to_numpy(), np.round(y_hat_dev))\n",
        "#       if cur_accuracy > best_accuracy:\n",
        "#           best_accuracy = cur_accuracy\n",
        "#           best_model = fitted_ridge\n",
        "#       # fit (using Lasso Regression), predict, and score\n",
        "#       fitted_lasso = Lasso(alpha=cur_alpha).fit(x_train, y_train_lr)\n",
        "#       y_hat_dev = fitted_lasso.predict(x_dev).reshape(1,-1)[0]\n",
        "#       cur_accuracy = accuracy_score(y_dev['affordable'].to_numpy(), np.round(y_hat_dev))\n",
        "#       if cur_accuracy > best_accuracy:\n",
        "#           best_accuracy = cur_accuracy\n",
        "#           best_model = fitted_lasso\n",
        "#   print(\"best_model:\", best_model, \"yielded accuracy of:\", best_accuracy)"
      ],
      "metadata": {
        "id": "wF0yLlZwmvRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4 : Binary Logistic Regression"
      ],
      "metadata": {
        "id": "_V4m8c0by9tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Simply fitting the model into LogisticRegression model\n",
        "#   from sklearn.linear_model import LogisticRegression\n",
        "#   lr = LogisticRegression()\n",
        "#   lr.fit(x_train, y_train['affordable'])\n",
        "\n",
        "### Finding the intital accuracy of out logistic regression model\n",
        "#   y_hat_dev = lr.predict(x_dev)\n",
        "#   initial_score = accuracy_score(y_dev['affordable'].to_numpy(), y_hat_dev)\n",
        "#   print(\"our initial logistic regression model yielded accuracy score of:\", initial_score)\n",
        "\n",
        "### Now we are appling lasso and ridge to out model with different values of alpha for best accuracy model\n",
        "#   best_accuracy = -1\n",
        "#   best_model = None\n",
        "#   c_vals = [1, 10, 100, 1000, 10000, 100000, 1000000, 10000000]\n",
        "#   num_iters = [5, 10, 100, 1000, 5000]\n",
        "#   for c_val in c_vals:\n",
        "#       for num_iter in num_iters:\n",
        "#           lr = LogisticRegression(C=c_val, solver='liblinear', max_iter=num_iter)\n",
        "#           lr.fit(x_train, y_train['affordable'])\n",
        "#           y_hat_dev = lr.predict(x_dev)\n",
        "#           cur_accuracy = accuracy_score(y_dev['affordable'].to_numpy(), y_hat_dev)\n",
        "#           if cur_accuracy > best_accuracy:\n",
        "#               best_accuracy = cur_accuracy\n",
        "#               best_model = lr\n",
        "#   print(\"best logistic regression model:\", lr, \"yielded an accuracy score:\", best_accuracy)\n",
        "#   print(\"its learned coefficients:\", len(best_model.coef_[0]))\n",
        "#   print(\"the coefficients align with our features:\", x_dev.shape)\n",
        "\n",
        "### COnclusion from this.\n",
        "# logistic regression should not be viewed as being superior to linear regression.\n",
        "# it should be viewed as a solution to a different type of problem -- classification, not regression."
      ],
      "metadata": {
        "id": "nITDSY4Sy9DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 5 : Multiclass Classification(The Real Challenge)"
      ],
      "metadata": {
        "id": "yIwGqsha0NwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Previously we were just perdicting for binary class, now we are predicting for multi class.\n",
        "# budget: < 80\n",
        "# affordable: 80 < x < 120\n",
        "# average: 120 < x < 180\n",
        "# expensive: 180 < x < 240\n",
        "# very expensive: 240 < x\n",
        "\n",
        "### creates multi-class labels for training\n",
        "#   x_train_multiclass = x_train.copy()\n",
        "#   x_train_multiclass['price_level'] = pd.cut(df_train['price'],[0,80,120,180,240,float('inf')], labels=[0,1,2,3,4])\n",
        "# Extracting and removing label column.\n",
        "#   y_train_multiclass = pd.DataFrame(data=x_train_multiclass['price_level'], columns=[\"price_level\"])\n",
        "#   x_train_multiclass = x_train_multiclass.drop(['price_level'], axis=1)\n",
        "\n",
        "### creats multi-class labels for dev\n",
        "#   x_dev_multiclass = x_dev.copy()\n",
        "#   x_dev_multiclass['price_level'] = pd.cut(df_dev['price'],[0,80,120,180,240,float('inf')], labels=[0,1,2,3,4])\n",
        "# Extracting and removing label column.\n",
        "#   y_dev_multiclass = pd.DataFrame(data=x_dev_multiclass['price_level'], columns=[\"price_level\"])\n",
        "#   x_dev_multiclass = x_dev_multiclass.drop(['price_level'], axis=1)\n",
        "\n",
        "### Here we are appling lasso and ridge to out model with different values of alpha for best accuracy model\n",
        "#   best_accuracy = -1\n",
        "#   best_model = None\n",
        "#   c_vals = [1, 10, 100, 1000, 10000]\n",
        "#   num_iters = [10, 100, 1000, 5000]\n",
        "#   for c_val in c_vals:\n",
        "#       for num_iter in num_iters:\n",
        "#           lr = LogisticRegression(solver=\"lbfgs\", max_iter=10000)\n",
        "#           lr.fit(x_train_multiclass, y_train_multiclass['price_level'])\n",
        "#           y_hat_dev = lr.predict(x_dev_multiclass)\n",
        "#           cur_accuracy = accuracy_score(y_dev_multiclass['price_level'].to_numpy(), y_hat_dev)\n",
        "#           print(cur_accuracy)\n",
        "#           if cur_accuracy > best_accuracy:\n",
        "#               best_accuracy = cur_accuracy\n",
        "#               best_model = lr\n",
        "\n",
        "### Printing the best model detals.\n",
        "#   print(\"best logistic regression model:\", lr, \"yielded an accuracy score:\", best_accuracy)\n",
        "#   print(\"its learned coefficients:\", len(best_model.coef_[0]))\n",
        "#   print(\"the coefficients align with our features:\", x_dev.shape)\n",
        "\n",
        "### Coefficient for each columns.\n",
        "#   for i in range(len(x_dev.columns)):\n",
        "#       print(\"feature:\", x_dev.columns[i], \"; coef:\", best_model.coef_[0][i])"
      ],
      "metadata": {
        "id": "Gt_U8j3Az7uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hqCaAWYwuS-"
      },
      "source": [
        "\n",
        "\n",
        "# Exercise 01 : Binary Logistic Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMTZqILywfPK"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUVAJCMHw5lL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e0815b-b1f3-4542-a25d-515ff83d8e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-DUdL5wxN8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "714f300a-b7f2-4792-ac11-30fc2017f1b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    User ID  Age  EstimatedSalary  Purchased\n",
              "0  15624510   19            19000          0\n",
              "1  15810944   35            20000          0\n",
              "2  15668575   26            43000          0\n",
              "3  15603246   27            57000          0\n",
              "4  15804002   19            76000          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5160580-8de5-4aa4-af6d-6004d518298a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5160580-8de5-4aa4-af6d-6004d518298a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5160580-8de5-4aa4-af6d-6004d518298a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5160580-8de5-4aa4-af6d-6004d518298a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9515c94e-64c3-4928-a91b-661dcc278713\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9515c94e-64c3-4928-a91b-661dcc278713')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9515c94e-64c3-4928-a91b-661dcc278713 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/BuyComputer.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv0PLdt51m6f"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBAWW98exoST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8bdd5de4-c4c1-4066-8521-9a86a4e96d28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  EstimatedSalary  Purchased\n",
              "0   19            19000          0\n",
              "1   35            20000          0\n",
              "2   26            43000          0\n",
              "3   27            57000          0\n",
              "4   19            76000          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a995cd59-fafb-4479-b927-a0c0d47355d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a995cd59-fafb-4479-b927-a0c0d47355d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a995cd59-fafb-4479-b927-a0c0d47355d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a995cd59-fafb-4479-b927-a0c0d47355d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b3fb58e-5aa5-46ff-a741-43d4b51fc608\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b3fb58e-5aa5-46ff-a741-43d4b51fc608')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b3fb58e-5aa5-46ff-a741-43d4b51fc608 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df = df.drop('User ID', axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEigGh662iLq"
      },
      "outputs": [],
      "source": [
        "data = df[['Age', 'EstimatedSalary']]\n",
        "labels = df[['Purchased']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Mv9U8VH1yUiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 01\n"
      ],
      "metadata": {
        "id": "svggRzPJGEYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "99OCPfv9yddW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(random_state=1)\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "XhB1acLhF6S9",
        "outputId": "9eb04e59-69d6-4938-d18a-e3014de181c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxUrUHr7F78Y",
        "outputId": "e7d5ee9e-d117-4a35-b039-93526057f9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 02\n"
      ],
      "metadata": {
        "id": "sQkIw840GANv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.api import OLS\n",
        "model = OLS(y_train, X_train)\n",
        "results = model.fit()\n",
        "results.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "KeT9Me3HyubY",
        "outputId": "aaad2a0b-fce3-42c3-f0dd-80bd0679306f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:              Purchased   R-squared (uncentered):                   0.277\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.272\n",
              "Method:                 Least Squares   F-statistic:                              60.91\n",
              "Date:                Fri, 06 Oct 2023   Prob (F-statistic):                    4.02e-23\n",
              "Time:                        17:40:35   Log-Likelihood:                         -238.43\n",
              "No. Observations:                 320   AIC:                                      480.9\n",
              "Df Residuals:                     318   BIC:                                      488.4\n",
              "Df Model:                           2                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1             0.2601      0.029      9.008      0.000       0.203       0.317\n",
              "x2             0.1453      0.029      5.033      0.000       0.089       0.202\n",
              "==============================================================================\n",
              "Omnibus:                       11.102   Durbin-Watson:                   1.000\n",
              "Prob(Omnibus):                  0.004   Jarque-Bera (JB):                5.594\n",
              "Skew:                           0.060   Prob(JB):                       0.0610\n",
              "Kurtosis:                       2.364   Cond. No.                         1.15\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
              "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Purchased</td>    <th>  R-squared (uncentered):</th>      <td>   0.277</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.272</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   60.91</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 06 Oct 2023</td> <th>  Prob (F-statistic):</th>          <td>4.02e-23</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:40:35</td>     <th>  Log-Likelihood:    </th>          <td> -238.43</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   320</td>      <th>  AIC:               </th>          <td>   480.9</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   318</td>      <th>  BIC:               </th>          <td>   488.4</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>    0.2601</td> <td>    0.029</td> <td>    9.008</td> <td> 0.000</td> <td>    0.203</td> <td>    0.317</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>    0.1453</td> <td>    0.029</td> <td>    5.033</td> <td> 0.000</td> <td>    0.089</td> <td>    0.202</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>11.102</td> <th>  Durbin-Watson:     </th> <td>   1.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.004</td> <th>  Jarque-Bera (JB):  </th> <td>   5.594</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.060</td> <th>  Prob(JB):          </th> <td>  0.0610</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.364</td> <th>  Cond. No.          </th> <td>    1.15</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &    Purchased     & \\textbf{  R-squared (uncentered):}      &     0.277   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.272   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     60.91   \\\\\n\\textbf{Date:}             & Fri, 06 Oct 2023 & \\textbf{  Prob (F-statistic):}          &  4.02e-23   \\\\\n\\textbf{Time:}             &     17:40:35     & \\textbf{  Log-Likelihood:    }          &   -238.43   \\\\\n\\textbf{No. Observations:} &         320      & \\textbf{  AIC:               }          &     480.9   \\\\\n\\textbf{Df Residuals:}     &         318      & \\textbf{  BIC:               }          &     488.4   \\\\\n\\textbf{Df Model:}         &           2      & \\textbf{                     }          &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{x1} &       0.2601  &        0.029     &     9.008  &         0.000        &        0.203    &        0.317     \\\\\n\\textbf{x2} &       0.1453  &        0.029     &     5.033  &         0.000        &        0.089    &        0.202     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 11.102 & \\textbf{  Durbin-Watson:     } &    1.000  \\\\\n\\textbf{Prob(Omnibus):} &  0.004 & \\textbf{  Jarque-Bera (JB):  } &    5.594  \\\\\n\\textbf{Skew:}          &  0.060 & \\textbf{  Prob(JB):          } &   0.0610  \\\\\n\\textbf{Kurtosis:}      &  2.364 & \\textbf{  Cond. No.          } &     1.15  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_dev = results.predict(exog=X_test)\n",
        "new_accuracy = accuracy_score(y_test, np.round(y_hat_dev))\n",
        "print(f'Accuracy : {new_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwOu1mktyw_3",
        "outputId": "6ce29557-8f1a-4ec2-9eee-ee793f3c1b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.6375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6_1juCMy4lt",
        "outputId": "29e864e4-6e27-4810-8dad-7aa5c09028bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90        52\n",
            "           1       0.90      0.68      0.78        28\n",
            "\n",
            "    accuracy                           0.86        80\n",
            "   macro avg       0.88      0.82      0.84        80\n",
            "weighted avg       0.87      0.86      0.86        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "best_accuracy = -1\n",
        "best_model = None\n",
        "\n",
        "for cur_alpha in [0.001, .01, .05, .1, .5, 1, 5, 10, 50, 100, 500]:\n",
        "    # fit (using Ridge Regression), predict, and score\n",
        "    fitted_ridge = Ridge(alpha=cur_alpha).fit(X_train, y_train)\n",
        "    y_hat_dev = fitted_ridge.predict(X_test).reshape(1,-1)[0]\n",
        "    cur_accuracy = accuracy_score(y_test['Purchased'].to_numpy(), np.round(y_hat_dev))\n",
        "    if cur_accuracy > best_accuracy:\n",
        "        best_accuracy = cur_accuracy\n",
        "        best_model = fitted_ridge\n",
        "\n",
        "    # fit (using Lasso Regression), predict, and score\n",
        "    fitted_lasso = Lasso(alpha=cur_alpha).fit(X_train, y_train)\n",
        "    y_hat_dev = fitted_lasso.predict(X_test).reshape(1,-1)[0]\n",
        "    cur_accuracy = accuracy_score(y_test['Purchased'].to_numpy(), np.round(y_hat_dev))\n",
        "    if cur_accuracy > best_accuracy:\n",
        "        best_accuracy = cur_accuracy\n",
        "        best_model = fitted_lasso\n",
        "print(\"best_model:\", best_model, \"yielded accuracy of:\", best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFNP9q-eD8k9",
        "outputId": "c2419695-275f-4b23-be83-c0c7688a00d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model: Lasso(alpha=0.01) yielded accuracy of: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 02 : Multiclass logistic regression"
      ],
      "metadata": {
        "id": "5s1H18p6Kd4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "WCFX6qqGGzf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = iris.data\n",
        "feature = iris.target\n",
        "print(\"Feature names:\", iris.feature_names)\n",
        "print(\"Target names:\", iris.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6EzvMbbLkQv",
        "outputId": "7bbee7e1-16f3-41aa-f70b-b543719856a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Target names: ['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, feature, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GScZutttLlcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_vals = [1, 10, 100, 1000, 10000]\n",
        "num_iters = [10, 100, 1000, 5000]\n",
        "best_accuracy = -1\n",
        "best_model = None\n",
        "\n",
        "for c_val in c_vals:\n",
        "    for num_iter in num_iters:\n",
        "        lr = LogisticRegression(solver=\"lbfgs\", max_iter=num_iter, C=c_val)\n",
        "        lr.fit(X_train, y_train)\n",
        "        y_hat_dev = lr.predict(X_test)\n",
        "        cur_accuracy = accuracy_score(y_test, y_hat_dev)\n",
        "        print(f\"C: {c_val}, Num Iter: {num_iter}, Accuracy: {cur_accuracy}\")\n",
        "        if cur_accuracy > best_accuracy:\n",
        "            best_accuracy = cur_accuracy\n",
        "            best_model = lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiIPJQSJL664",
        "outputId": "983bb5f2-3940-4a7c-dcf4-b18e2e655437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: 1, Num Iter: 10, Accuracy: 1.0\n",
            "C: 1, Num Iter: 100, Accuracy: 1.0\n",
            "C: 1, Num Iter: 1000, Accuracy: 1.0\n",
            "C: 1, Num Iter: 5000, Accuracy: 1.0\n",
            "C: 10, Num Iter: 10, Accuracy: 1.0\n",
            "C: 10, Num Iter: 100, Accuracy: 1.0\n",
            "C: 10, Num Iter: 1000, Accuracy: 1.0\n",
            "C: 10, Num Iter: 5000, Accuracy: 1.0\n",
            "C: 100, Num Iter: 10, Accuracy: 1.0\n",
            "C: 100, Num Iter: 100, Accuracy: 1.0\n",
            "C: 100, Num Iter: 1000, Accuracy: 1.0\n",
            "C: 100, Num Iter: 5000, Accuracy: 1.0\n",
            "C: 1000, Num Iter: 10, Accuracy: 1.0\n",
            "C: 1000, Num Iter: 100, Accuracy: 1.0\n",
            "C: 1000, Num Iter: 1000, Accuracy: 1.0\n",
            "C: 1000, Num Iter: 5000, Accuracy: 1.0\n",
            "C: 10000, Num Iter: 10, Accuracy: 1.0\n",
            "C: 10000, Num Iter: 100, Accuracy: 1.0\n",
            "C: 10000, Num Iter: 1000, Accuracy: 1.0\n",
            "C: 10000, Num Iter: 5000, Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Model Accuracy:\", best_accuracy)\n",
        "print(\"Best Model Parameters:\", best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAgUznpIOQ7Z",
        "outputId": "9ee545c7-f2cf-42f4-c66e-4b7ff018d6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Accuracy: 1.0\n",
            "Best Model Parameters: LogisticRegression(C=1, max_iter=10)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4hqCaAWYwuS-",
        "5s1H18p6Kd4B"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}